{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "import pandas as pd\n",
    "import unicodedata\n",
    "import string\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gerando Dashboards em: /home/guisales/projeto-fort/teste_1\n"
     ]
    }
   ],
   "source": [
    "selected_path = \"\"\n",
    "\n",
    "def select_folder():\n",
    "    global selected_path \n",
    "    folder = filedialog.askdirectory()\n",
    "    selected_path = folder \n",
    "    entry_folder.delete(0, \"end\") \n",
    "    entry_folder.insert(0, folder) \n",
    "\n",
    "def generate_dashboard():\n",
    "    if selected_path:\n",
    "        print(\"Gerando Dashboards em:\", selected_path)\n",
    "        window.destroy()\n",
    "\n",
    "window = tk.Tk()\n",
    "window.geometry('640x360')\n",
    "window.title(\"Selecionar Pasta\")\n",
    "\n",
    "label = tk.Label(window, text=\"Digitar Caminho:\", padx=10)\n",
    "label.pack(side='left')\n",
    "\n",
    "entry_folder = tk.Entry(window)\n",
    "entry_folder.pack(side='left')\n",
    "\n",
    "button_ok = tk.Button(window, text=\"Procurar Caminho\", command=select_folder, padx=70)\n",
    "button_ok.pack(side='right')\n",
    "\n",
    "button_save = tk.Button(window, text=\"Salvar Caminho\", command=lambda: button_generate.place(x=240, y=310))\n",
    "button_save.pack(side='bottom', pady=70)\n",
    "\n",
    "button_generate = tk.Button(window, text=\"Gerar Dashboards\", command=generate_dashboard, padx=30)\n",
    "button_generate.pack_forget()\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_any_csv(path: str):\n",
    "    count_csv_files = 0\n",
    "    for file in os.listdir(path):\n",
    "        if file.split('.')[-1] == 'csv':\n",
    "            count_csv_files += 1\n",
    "\n",
    "    if count_csv_files == 0:\n",
    "        return ValueError('Não há arquivos .csv para gerar o(s) dashboard(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = ''.join([c for c in unicodedata.normalize('NFKD', text) if not unicodedata.combining(c)])\n",
    "    \n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    text = text.translate(translator)\n",
    "    \n",
    "    text = text.lower()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_note(note, kind=None):\n",
    "    if kind == 'to_int':\n",
    "        match note:\n",
    "            case 'otimo':\n",
    "                return 5\n",
    "            case 'bom':\n",
    "                return 4\n",
    "            case 'regular':\n",
    "                return 3\n",
    "            case 'ruim':\n",
    "                return 2\n",
    "            case 'pessimo':\n",
    "                return 1\n",
    "    else:\n",
    "        match note:\n",
    "            case 5:\n",
    "                return 'Ótimo'\n",
    "            case 4:\n",
    "                return 'Bom'\n",
    "            case 3:\n",
    "                return 'Regular'\n",
    "            case 2:\n",
    "                return 'Ruim'\n",
    "            case 1:\n",
    "                return 'Péssimo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aval_data(path: str):\n",
    "    \n",
    "    avals = []\n",
    "    \n",
    "    for aval in os.listdir(path):\n",
    "        df = pd.read_csv(f'{path}/{aval}')\n",
    "        avals.append({\n",
    "        'professor': preprocess_text(df['professor'].to_string(index=False)),\n",
    "        'escola': preprocess_text(df['escola'].to_string(index=False)),\n",
    "        'data': df['data'].to_string(index=False),\n",
    "        'turno': preprocess_text(df['turno'].to_string(index=False)),\n",
    "        'ano': preprocess_text(df['ano'].to_string(index=False)),\n",
    "        'autoavaliação': preprocess_text(df['autoavaliação'].to_string(index=False)),\n",
    "        'avaliação_curso': preprocess_text(df['avaliação do curso'].to_string(index=False)),\n",
    "        'nome_formador': preprocess_text(df['nome do formador'].to_string(index=False)),\n",
    "        'dominio_conteudo': preprocess_text(df['domínio do conteúdo'].to_string(index=False)),\n",
    "        'capacidade_lideranca': preprocess_text(df['capacidade de liderança'].to_string(index=False)),\n",
    "        'clareza': preprocess_text(df['clareza'].to_string(index=False)),\n",
    "        'relacionamento': preprocess_text(df['relacionamento'].to_string(index=False)),\n",
    "        'metodologia': preprocess_text(df['metodologia trabalhada'].to_string(index=False)),\n",
    "        'pontos_positivos': preprocess_text(df['pontos positivos'].to_string(index=False)),\n",
    "        'pontos_negativos': preprocess_text(df['pontos negativos'].to_string(index=False)),\n",
    "        'sugestoes': preprocess_text(df['sugestões'].to_string(index=False)),\n",
    "        'experiencia': preprocess_text(df['experiência'].to_string(index=False))\n",
    "        })\n",
    "        \n",
    "    return avals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_course_aval(all_avals: list):\n",
    "\n",
    "    dom_cont = 0\n",
    "    cap_lider = 0\n",
    "    clareza = 0\n",
    "    relac = 0\n",
    "    metodo = 0\n",
    "    count_avals = 0\n",
    "\n",
    "    for aval in all_avals:\n",
    "        dom_cont += transform_note(aval['dominio_conteudo'], 'to_int')\n",
    "        cap_lider += transform_note(aval['capacidade_lideranca'], 'to_int')\n",
    "        clareza += transform_note(aval['clareza'], 'to_int')\n",
    "        relac += transform_note(aval['relacionamento'], 'to_int')\n",
    "        metodo += transform_note(aval['metodologia'], 'to_int')\n",
    "        count_avals += 1\n",
    "\n",
    "    return dom_cont, cap_lider, clareza, relac, metodo, count_avals, count_avals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_professor_aval(all_avals: list, professor_name: str):\n",
    "    \n",
    "    professor_avals = [d for d in all_avals if d.get('professor') == professor_name]\n",
    "    \n",
    "    dom_cont = 0\n",
    "    cap_lider = 0\n",
    "    clareza = 0\n",
    "    relac = 0\n",
    "    metodo = 0\n",
    "    count_avals = 0\n",
    "\n",
    "    for aval in professor_avals:\n",
    "        dom_cont += transform_note(aval['dominio_conteudo'], 'to_int')\n",
    "        cap_lider += transform_note(aval['capacidade_lideranca'], 'to_int')\n",
    "        clareza += transform_note(aval['clareza'], 'to_int')\n",
    "        relac += transform_note(aval['relacionamento'], 'to_int')\n",
    "        metodo += transform_note(aval['metodologia'], 'to_int')\n",
    "        count_avals += 1\n",
    "\n",
    "    return dom_cont, cap_lider, clareza, relac, metodo, count_avals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_professors(all_avals: list) -> list:\n",
    "    \n",
    "    all_professors = set()\n",
    "    \n",
    "    for aval in all_avals:\n",
    "        all_professors.add(aval['professor'])\n",
    "    \n",
    "    return list(all_professors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'professor': 'guilherme',\n",
       "  'escola': 'modelo',\n",
       "  'data': '21/09/2001',\n",
       "  'turno': 'manha',\n",
       "  'ano': '9',\n",
       "  'autoavaliação': '10',\n",
       "  'avaliação_curso': '10',\n",
       "  'nome_formador': 'noemy vascocnelos boto',\n",
       "  'dominio_conteudo': 'otimo',\n",
       "  'capacidade_lideranca': 'otimo',\n",
       "  'clareza': 'otimo',\n",
       "  'relacionamento': 'otimo',\n",
       "  'metodologia': 'otimo',\n",
       "  'pontos_positivos': 'fala bem',\n",
       "  'pontos_negativos': 'escuta mal',\n",
       "  'sugestoes': 'trabalhar outros livros',\n",
       "  'experiencia': 'achei bastante proveitoso'},\n",
       " {'professor': 'ive',\n",
       "  'escola': 'christus',\n",
       "  'data': '22/08/1996',\n",
       "  'turno': 'intergal',\n",
       "  'ano': '8',\n",
       "  'autoavaliação': '9',\n",
       "  'avaliação_curso': '9',\n",
       "  'nome_formador': 'tupac amaru shakur segundo',\n",
       "  'dominio_conteudo': 'bom',\n",
       "  'capacidade_lideranca': 'regular',\n",
       "  'clareza': 'otimo',\n",
       "  'relacionamento': 'ruim',\n",
       "  'metodologia': 'bom',\n",
       "  'pontos_positivos': 'fala alto',\n",
       "  'pontos_negativos': 'escuta baixo',\n",
       "  'sugestoes': 'trabalhar outros livros e trazer mais materiais',\n",
       "  'experiencia': 'odeie o curso achei cansativo e chato'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste = get_aval_data(selected_path)\n",
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['professor', 'escola', 'data', 'turno', 'ano', 'autoavaliação', 'avaliação_curso', 'nome_formador', 'dominio_conteudo', 'capacidade_lideranca', 'clareza', 'relacionamento', 'metodologia', 'pontos_positivos', 'pontos_negativos', 'sugestoes', 'experiencia'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ive', 'guilherme']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_professors(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 8, 10, 7, 9, 2, 2)\n"
     ]
    }
   ],
   "source": [
    "print(get_course_aval(teste))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 3, 5, 2, 4, 1)\n"
     ]
    }
   ],
   "source": [
    "print(get_professor_aval(teste, 'ive'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(get_course_aval(teste))\n",
    "data = data.T\n",
    "data.columns =['dominio_conteudo', 'capacidade_lideranca', 'clareza', 'relacionamento', 'metodologia', 'count_avals', 'count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dominio_conteudo</th>\n",
       "      <th>capacidade_lideranca</th>\n",
       "      <th>clareza</th>\n",
       "      <th>relacionamento</th>\n",
       "      <th>metodologia</th>\n",
       "      <th>count_avals</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dominio_conteudo  capacidade_lideranca  clareza  relacionamento  \\\n",
       "0                 9                     8       10               7   \n",
       "\n",
       "   metodologia  count_avals  count  \n",
       "0            9            2      2  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dominio_conteudo', 9),\n",
       " ('capacidade_lideranca', 8),\n",
       " ('clareza', 10),\n",
       " ('relacionamento', 7),\n",
       " ('metodologia', 9),\n",
       " ('count_avals', 2),\n",
       " ('count', 2)]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "columns = ['dominio_conteudo', 'capacidade_lideranca', 'clareza', 'relacionamento', 'metodologia', 'count_avals', 'count']\n",
    "\n",
    "data_for_plot = []\n",
    "for value, column in zip(get_course_aval(teste), columns):\n",
    "    data_for_plot.append((column, value))\n",
    "\n",
    "data_for_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['professor', 'escola', 'data', 'turno', 'ano', 'autoavaliação', 'avaliação_curso', 'nome_formador', 'dominio_conteudo', 'capacidade_lideranca', 'clareza', 'relacionamento', 'metodologia', 'pontos_positivos', 'pontos_negativos', 'sugestoes', 'experiencia'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def aval_note(all_avals, area, transform):\n",
    "    final_note = 0\n",
    "    for course_aval in all_avals:\n",
    "        final_note += int(course_aval[f'{area}'])\n",
    "\n",
    "    if transform == True:\n",
    "        return transform_note(math.ceil(final_note/(2*len(all_avals))))\n",
    "    if transform == False:\n",
    "        return math.ceil(final_note/(2*len(all_avals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ótimo'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aval_note(teste, 'avaliação_curso', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "quality = ['Ótimo', 'Bom', 'Regular', 'Ruim', 'Pessímo']\n",
    "def get_note_distr(all_avals, area):\n",
    "    all_notes = []\n",
    "    data = []\n",
    "    for aval in all_avals:\n",
    "        all_notes.append(aval[f'{area}'])\n",
    "    \n",
    "    for note in quality:\n",
    "        data.append((note, all_notes.count(f'{preprocess_text(note)}')))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Ótimo', 2), ('Bom', 0), ('Regular', 0), ('Ruim', 0), ('Pessímo', 0)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_note_distr(teste, 'clareza')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'professor': 'guilherme',\n",
       " 'escola': 'modelo',\n",
       " 'data': '21/09/2001',\n",
       " 'turno': 'manha',\n",
       " 'ano': '9',\n",
       " 'autoavaliação': '10',\n",
       " 'avaliação_curso': '10',\n",
       " 'nome_formador': 'noemy vascocnelos boto',\n",
       " 'dominio_conteudo': 'otimo',\n",
       " 'capacidade_lideranca': 'otimo',\n",
       " 'clareza': 'otimo',\n",
       " 'relacionamento': 'otimo',\n",
       " 'metodologia': 'otimo',\n",
       " 'pontos_positivos': 'fala bem',\n",
       " 'pontos_negativos': 'escuta mal',\n",
       " 'sugestoes': 'trabalhar outros livros',\n",
       " 'experiencia': 'achei bastante proveitoso'}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_sugests(all_avals):\n",
    "    sugestions = []\n",
    "    for aval in all_avals:\n",
    "        sugestions.append(aval['experiencia'])\n",
    "    return sugestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['achei bastante proveitoso', 'odeie o curso achei cansativo e chato']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_sugests(teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'professor': 'guilherme',\n",
       "  'escola': 'modelo',\n",
       "  'data': '21/09/2001',\n",
       "  'turno': 'manha',\n",
       "  'ano': '9',\n",
       "  'autoavaliação': '10',\n",
       "  'avaliação_curso': '10',\n",
       "  'nome_formador': 'noemy vascocnelos boto',\n",
       "  'dominio_conteudo': 'otimo',\n",
       "  'capacidade_lideranca': 'otimo',\n",
       "  'clareza': 'otimo',\n",
       "  'relacionamento': 'otimo',\n",
       "  'metodologia': 'otimo',\n",
       "  'pontos_positivos': 'fala bem',\n",
       "  'pontos_negativos': 'escuta mal',\n",
       "  'sugestoes': 'trabalhar outros livros',\n",
       "  'experiencia': 'achei bastante proveitoso'},\n",
       " {'professor': 'ive',\n",
       "  'escola': 'christus',\n",
       "  'data': '22/08/1996',\n",
       "  'turno': 'intergal',\n",
       "  'ano': '8',\n",
       "  'autoavaliação': '9',\n",
       "  'avaliação_curso': '9',\n",
       "  'nome_formador': 'tupac amaru shakur segundo',\n",
       "  'dominio_conteudo': 'bom',\n",
       "  'capacidade_lideranca': 'regular',\n",
       "  'clareza': 'otimo',\n",
       "  'relacionamento': 'ruim',\n",
       "  'metodologia': 'bom',\n",
       "  'pontos_positivos': 'fala alto',\n",
       "  'pontos_negativos': 'escuta baixo',\n",
       "  'sugestoes': 'trabalhar outros livros e trazer mais materiais',\n",
       "  'experiencia': 'odeie o curso achei cansativo e chato'}]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fort-dashboard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
